{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import tqdm\n",
    "\n",
    "\n",
    "class conllu_file:\n",
    "    def __init__(self, file_name):\n",
    "        data_file = io.open(file_name, 'r', encoding='utf-8')\n",
    "        self.sentences = []\n",
    "        print('Started Sentences')\n",
    "        for sentence in tqdm.tqdm(conllu.parse_incr(data_file)):\n",
    "            self.sentences.append(sentence)\n",
    "        print('Finished Sentences')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "import numpy\n",
    "import operator\n",
    "class hmm_tagger:\n",
    "    \n",
    "    def __init__(self, file, token, tag):\n",
    "        self.sentences = file.sentences\n",
    "        self.token = token\n",
    "        self.tag = tag\n",
    "        \n",
    "        self.tags = {'START': 0, 'END': 1}\n",
    "        self.tag_list = ['START', 'END']\n",
    "        print('Started Tags')\n",
    "        for sentence in tqdm.tqdm(self.sentences):\n",
    "            for word in sentence:\n",
    "                if word[tag] not in self.tags.keys():\n",
    "                    self.tags[word[tag]] = len(self.tags)\n",
    "                    self.tag_list.append(word[tag])\n",
    "        print('Finished Tags')\n",
    "        \n",
    "        self.words = {}\n",
    "        print('Started Words')\n",
    "        for sentence in tqdm.tqdm(self.sentences):\n",
    "            for word in sentence:\n",
    "                if word[token] not in self.words.keys():\n",
    "                    self.words[word[token]] = len(self.words)\n",
    "        print('Finished Words')\n",
    "        \n",
    "        self.tag_counts = numpy.zeros(len(self.tags))\n",
    "        self.trans_probs = numpy.zeros((len(self.tags), len(self.tags)))\n",
    "        self.emiss_probs = numpy.zeros((len(self.words), len(self.tags)))\n",
    "        self.avg_emis_probs = numpy.zeros(len(self.tags))\n",
    "    \n",
    "    def predict(self, sentence):\n",
    "        probs = numpy.zeros(len(self.tags))\n",
    "        probs[self.tags['START']] = 1\n",
    "        tag_seqs = [[] for i in range(len(self.tags))]\n",
    "        for word in sentence:\n",
    "            probs = self.trans_probs * probs[:, numpy.newaxis]\n",
    "            if word[self.token] in self.words.keys():\n",
    "                probs = probs * self.emiss_probs[self.words[word[self.token]], :]\n",
    "            elif word[self.token][0].isdigit():\n",
    "                probs = probs * (self._fix('NUM') if self.tag == 'upostag' else self._fix('CD'))\n",
    "            elif '.' in word[self.token]:\n",
    "                probs = probs * (self._fix('X') if self.tag == 'upostag' else self._fix('ADD'))\n",
    "            elif word[self.token] == '-':\n",
    "                probs = probs * (self._fix('PUNCT') if self.tag == 'upostag' else self._fix('NFP'))\n",
    "            elif word[self.token].isupper() and len(tag_seqs) != 0:\n",
    "                 probs = probs * (self._fix('PROPN') if self.tag == 'upostag' else self._fix('NNP'))\n",
    "            else:\n",
    "                probs = probs * self.avg_emis_probs\n",
    "            indices = numpy.argmax(probs, axis = 0)\n",
    "            probs = numpy.amax(probs, axis = 0)\n",
    "            tag_seqs = [tag_seqs[indices[i]] + [self.tag_list[i]] for i in range(len(indices))]\n",
    "        return tag_seqs[numpy.argmax(probs)]\n",
    "    \n",
    "    def _fix(self, tag):\n",
    "        probs = numpy.zeros(len(self.tags))\n",
    "        probs[self.tags[tag]] = 1\n",
    "        return probs\n",
    "    \n",
    "    def train(self):\n",
    "        self._count_tags()\n",
    "        self._calc_trans_probs()\n",
    "        self._calc_emiss_probs()\n",
    "      \n",
    "    def _calc_emiss_probs(self):\n",
    "        print('Started Emission Probabilities')\n",
    "        for sentence in tqdm.tqdm(self.sentences):\n",
    "            for word in sentence:\n",
    "                self.emiss_probs[self.words[word[self.token]], self.tags[word[self.tag]]] += 1\n",
    "        print('Finished Emission Probabilities')\n",
    "        self.emiss_probs = self.emiss_probs / self.tag_counts\n",
    "        self.avg_emis_probs = numpy.mean(self.emiss_probs, axis = 0)\n",
    "        closed = ['DET', 'DT', 'PRON', 'PRP', 'AUX', 'MD', 'PUNCT', 'EX' ]\n",
    "        for tag in closed:\n",
    "            if tag in self.tags.keys():\n",
    "                self.avg_emis_probs[self.tags[tag]] = 0\n",
    "\n",
    "    def _calc_trans_probs(self):\n",
    "        print('Started Transition Probabilities')\n",
    "        for sentence in tqdm.tqdm(self.sentences):\n",
    "            self.trans_probs[self.tags['START'], self.tags[sentence[0][self.tag]]] += 1\n",
    "            self.trans_probs[self.tags[sentence[-1][self.tag]], self.tags['END']] += 1\n",
    "            for i in range(len(sentence) - 1):\n",
    "                self.trans_probs[self.tags[sentence[i][self.tag]], self.tags[sentence[i + 1][self.tag]]] += 1\n",
    "        print('Finished Transition Probabilities')\n",
    "        self.trans_probs = self.trans_probs / self.tag_counts[:, numpy.newaxis]\n",
    "\n",
    "    def _count_tags(self):\n",
    "        print('Started Tags Counts')\n",
    "        for sentence in tqdm.tqdm(self.sentences):\n",
    "            self.tag_counts[self.tags['START']] += 1\n",
    "            self.tag_counts[self.tags['END']] += 1\n",
    "            for word in sentence:\n",
    "                self.tag_counts[self.tags[word[self.tag]]] += 1\n",
    "        print('Finished Tags Counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(tagger, file):\n",
    "    total = 0\n",
    "    matches = 0\n",
    "    print('Started Testing')\n",
    "    for sentence in tqdm.tqdm(file.sentences):\n",
    "        total += len(sentence)\n",
    "        preds = tagger.predict(sentence)\n",
    "        matches += sum([preds[i] == sentence[i][tagger.tag] for i in range(len(sentence))])\n",
    "        print([(sentence[i]['upostag'], sentence[i]['xpostag'], sentence[i][tagger.token], preds[i]) for i in range(len(sentence)) if preds[i] != sentence[i][tagger.tag]])\n",
    "    print('Finished Testing')\n",
    "    return matches / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__== '__main__' :\n",
    "    file = conllu_file('en-ud-train.conllu')\n",
    "    tagger = hmm_tagger(file, 'form', 'upostag')\n",
    "    tagger.train()\n",
    "    file = conllu_file('en-ud-test.conllu')\n",
    "    print(test(tagger, file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
