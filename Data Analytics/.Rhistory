colors <- brewer.pal(6, "Spectral")
pairs(red[,1:11], col = colors[red$quality-2])
pairs(white[,1:11], col = colors[red$quality-2])
red.pca <- prcomp(red)
white.pca <- prcomp(white)
plot(red.pca$x[,1], red.pca$x[,2],col=red$quality)
plot(white.pca$x[,1], white.pca$x[,2],col=white$quality)
red$color <- colors[red$quality-2]
white$color <- colors[white$quality-2]
pairs(red[,1:11], col = red$color)
pairs(white[,1:11], col = white$color)
red.pca <- prcomp(red)
red.pca <- prcomp(red)
red.pca <- prcomp(red[1:11,])
red.pca <- prcomp(red[,1:11])
white.pca <- prcomp(white[,1:11])
plot(red.pca$x[,1], red.pca$x[,2],col=red$color)
plot(white.pca$x[,1], white.pca$x[,2],col=white$color)
train <- sample(nrow(white), 2000)
white.train <- white[train,]
white.test <- white[-train,]
lm <- lm(quality~., white.train)
summary(lm)
lm.preds <- predict(lm, white.test)
plot(lm.preds, white.test$quality)
lm.mse <- sum((lm.preds - white.test$quality)^2)
lm.mse
lm.preds
lm <- lm(quality~., white.train)
summary(lm)
lm.preds <- predict(lm, white.test)
plot(lm.preds, white.test$quality)
lm.mse <- sum((lm.preds - white.test$quality)^2)
lm.mse
white.test$quality
lm <- lm(as.numeric(quality)~., white.train)
summary(lm)
lm.preds <- predict(lm, white.test)
plot(lm.preds, white.test$quality)
lm.mse <- sum((lm.preds - white.test$quality)^2)
lm.mse
train <- sample(nrow(white), 2000)
white.train <- white[train,]
white.test <- white[-train,]
lm <- lm(as.numeric(quality)~., white.train)
summary(lm)
lm.preds <- predict(lm, white.test)
plot(lm.preds, white.test$quality)
lm.mse <- sum((lm.preds - white.test$quality)^2)
lm.mse
lm.preds
lm
lm <- lm(as.numeric(quality)~., white.train[1:12])
summary(lm)
lm.preds <- predict(lm, white.test)
plot(lm.preds, white.test$quality)
lm.mse <- sum((lm.preds - white.test$quality)^2)
lm.mse
library(randomForest)
library(forestFloor)
rf = randomForest(
quality~.,
white.train,
keep.inbag = TRUE,
importance = TRUE,
mtry = 3,
ntree = 1000,
)
library(randomForest)
library(forestFloor)
rf = randomForest(
quality~.,
white.train[1:12],
keep.inbag = TRUE,
importance = TRUE,
mtry = 3,
ntree = 1000,
)
rf.preds <- predict(rf, white.test)
plot(rf.preds, white.test$quality)
rf.mse <- sum((rf.preds - white.test$quality)^2)
rf.mse
ff = forestFloor(
rf = rf ,       # mandatory
X = white.train,              # mandatory
calc_np = FALSE,    # TRUE or FALSE both works, makes no difference
binary_reg = FALSE  # takes no effect here when rfo$type="regression"
)
plot(ff,  col = white.train$color  ,                 # forestFloor object
orderByImportance=FALSE    # if TRUE index sequence by importance, else by X column
)
randomForest::MDSplot(rf)
randomForest::MDSplot(rf$proximity)
library(randomForest)
library(forestFloor)
rf = randomForest(
quality~.,
white.train[1:12],
keep.inbag = TRUE,
importance = TRUE,
mtry = 3,
prox = TRUE,
ntree = 1000,
)
rf.preds <- predict(rf, white.test)
plot(rf.preds, white.test$quality)
rf.mse <- sum((rf.preds - white.test$quality)^2)
rf.mse
ff = forestFloor(
rf = rf ,       # mandatory
X = white.train,              # mandatory
calc_np = FALSE,    # TRUE or FALSE both works, makes no difference
binary_reg = FALSE  # takes no effect here when rfo$type="regression"
)
plot(ff,  col = white.train$color  ,                 # forestFloor object
orderByImportance=FALSE    # if TRUE index sequence by importance, else by X column
)
varImpPlot(rf)
plot(ff,  col = white.train$quality  ,                 # forestFloor object
orderByImportance=FALSE    # if TRUE index sequence by importance, else by X column
)
randomForest::MDSplot(rf$proximity)
randomForest::MDSplot(rf)
randomForest::MDSplot(rf, fac = as.factor(data$color))
randomForest::MDSplot(rf, fac = as.factor(white.train$quality))
randomForest::MDSplot(rf, fac = as.factor(white.train$quality), k=3)
rf$proximity
rf$coefs
randomForest::MDSplot(rf, fac = as.factor(white.train$quality), k=3)
randomForest::MDSplot(rf, fac = as.factor(white.train$quality), k=2)
randomForest::MDSplot(rf, fac = as.factor(white.train$quality), k=3)
data <- read.csv("G:\\My Drive\\HFI\\DataV12.csv")
library(randomForest)
library(forestFloor)
library(pROC)
library(bnlearn)
library(bnclassify)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(topicmodels)
library(tidytext)
data$LOG_BILL <- log10(data$BILL + 1)
data$LOG_CLAIMS <- log10(data$CLAIMS + 1)
data$LOG_RX_BILL <- log10(data$RX_BILL)
data$LOG_RX_CLAIMS <- log10(data$RX_CLAIMS)
data$APPROVAL[is.na(data$APPROVAL)] <- 0
data$OUTREACH[is.na(data$OUTREACH)] <- 0
data$APPROVAL <- as.factor(data$APPROVAL)
data$MEMBER_ID <- as.character(data$MEMBER_ID)
data$DEBIT_POINTS[is.na(data$DEBIT_POINTS)] <- 0
data$LOG_DEBIT_POINTS <- log10(data$DEBIT_POINTS + 1)
data$LOG_AVG_BILL <- data$LOG_BILL - data$LOG_CLAIMS
data$LOG_AVG_RX_BILL <- data$LOG_RX_BILL - data$LOG_RX_CLAIMS
quantities <- c("AGE", "LOG_AVG_BILL", "LOG_CLAIMS", "LOG_AVG_RX_BILL", "LOG_RX_CLAIMS")
quantities <- c("AGE", "LOG_AVG_RX_BILL", "LOG_RX_CLAIMS", "LOG_DEBIT_POINTS")
approval <- c("APPROVAL")
count <- nrow(data[data$APPROVAL == 1,])
corpus <- VCorpus(VectorSource(data$DIAGNOSIS))
dtm <- DocumentTermMatrix(corpus, control =
list(tolower = TRUE,
removeNumbers = TRUE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = FALSE))
data <- read.csv("G:\\My Drive\\HFI\\DataV12.csv")
library(randomForest)
library(forestFloor)
library(pROC)
library(bnlearn)
library(bnclassify)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(igraph)
library(lsa)
library(topicmodels)
library(tidytext)
library(RColorBrewer)
data$LOG_BILL <- log10(data$BILL + 1)
data$LOG_CLAIMS <- log10(data$CLAIMS + 1)
data$LOG_RX_BILL <- log10(data$RX_BILL)
data$LOG_RX_CLAIMS <- log10(data$RX_CLAIMS)
data$APPROVAL[is.na(data$APPROVAL)] <- 0
data$OUTREACH[is.na(data$OUTREACH)] <- 0
data$APPROVAL <- as.factor(data$APPROVAL)
data$MEMBER_ID <- as.character(data$MEMBER_ID)
data$DEBIT_POINTS[is.na(data$DEBIT_POINTS)] <- 0
data$LOG_DEBIT_POINTS <- log10(data$DEBIT_POINTS + 1)
data$LOG_AVG_BILL <- data$LOG_BILL - data$LOG_CLAIMS
data$LOG_AVG_RX_BILL <- data$LOG_RX_BILL - data$LOG_RX_CLAIMS
data$NUM_APPROVAL <- as.numeric(data$APPROVAL) - 1
data$INDEX <- seq.int(nrow(data))
quantities <- c("AGE", "LOG_AVG_RX_BILL", "LOG_RX_CLAIMS", "LOG_DEBIT_POINTS")
approval <- c("APPROVAL")
count <- nrow(data[data$APPROVAL == 1,])
corpus <- VCorpus(VectorSource(paste(data$DIAGNOSIS, data$REVENUE, sep = ' ')))
dtm <- DocumentTermMatrix(corpus, control =
list(tolower = TRUE,
removeNumbers = FALSE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE))
counts <- as.data.frame(matrix(0, ncol(dtm), 2))
row.names(counts) <- colnames(dtm)
colnames(counts) <- c("TOTAL", "APPROVAL_TOTAL")
for (i in 1:ncol(dtm)) {
counts$TOTAL[i] <- length(dtm[,i]$i)
counts$APPROVAL_TOTAL[i] <- sum(data$NUM_APPROVAL[dtm[,i]$i])
}
counts$CONFIDENCE <- 0
for (i in 1:nrow(counts)) {
test <- prop.test(c(counts$APPROVAL_TOTAL[i], count), c(counts$TOTAL[i], nrow(data)))
counts$CONFIDENCE[i] <- test$p.value
}
counts <- counts[order(counts$CONFIDENCE),]
dtm <- dtm[,row.names(counts)[1:1000]]
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
}
dtm <- apply(dtm, MARGIN = 2,convert_counts)
gc()
data <- read.csv("G:\\My Drive\\HFI\\DataV12.csv")
library(randomForest)
library(forestFloor)
library(pROC)
library(bnlearn)
library(bnclassify)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(igraph)
library(lsa)
library(topicmodels)
library(tidytext)
library(RColorBrewer)
data$LOG_BILL <- log10(data$BILL + 1)
data$LOG_CLAIMS <- log10(data$CLAIMS + 1)
data$LOG_RX_BILL <- log10(data$RX_BILL)
data$LOG_RX_CLAIMS <- log10(data$RX_CLAIMS)
data$APPROVAL[is.na(data$APPROVAL)] <- 0
data$OUTREACH[is.na(data$OUTREACH)] <- 0
data$APPROVAL <- as.factor(data$APPROVAL)
data$MEMBER_ID <- as.character(data$MEMBER_ID)
data$DEBIT_POINTS[is.na(data$DEBIT_POINTS)] <- 0
data$LOG_DEBIT_POINTS <- log10(data$DEBIT_POINTS + 1)
data$LOG_AVG_BILL <- data$LOG_BILL - data$LOG_CLAIMS
data$LOG_AVG_RX_BILL <- data$LOG_RX_BILL - data$LOG_RX_CLAIMS
data$NUM_APPROVAL <- as.numeric(data$APPROVAL) - 1
data$INDEX <- seq.int(nrow(data))
quantities <- c("AGE", "LOG_AVG_RX_BILL", "LOG_RX_CLAIMS", "LOG_DEBIT_POINTS")
approval <- c("APPROVAL")
count <- nrow(data[data$APPROVAL == 1,])
corpus <- VCorpus(VectorSource(paste(data$DIAGNOSIS, data$REVENUE, sep = ' ')))
dtm <- DocumentTermMatrix(corpus, control =
list(tolower = TRUE,
removeNumbers = FALSE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE))
counts <- as.data.frame(matrix(0, ncol(dtm), 2))
row.names(counts) <- colnames(dtm)
colnames(counts) <- c("TOTAL", "APPROVAL_TOTAL")
for (i in 1:ncol(dtm)) {
counts$TOTAL[i] <- length(dtm[,i]$i)
counts$APPROVAL_TOTAL[i] <- sum(data$NUM_APPROVAL[dtm[,i]$i])
}
counts$CONFIDENCE <- 0
for (i in 1:nrow(counts)) {
test <- prop.test(c(counts$APPROVAL_TOTAL[i], count), c(counts$TOTAL[i], nrow(data)))
counts$CONFIDENCE[i] <- test$p.value
}
counts <- counts[order(counts$CONFIDENCE),]
dtm <- dtm[,row.names(counts)[1:1000]]
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
}
dtm <- apply(dtm, MARGIN = 2,convert_counts)
dtm <- as.data.frame(dtm)
for (i in 1:ncol(dtm)) {
dtm[,i] <- as.factor(dtm[,i])
}
dtm$APPROVAL <- as.factor(data$APPROVAL)
tree.bayes <- tree.bayes(dtm, approval, colnames(dtm)[-length(dtm)])
tree.bayes.preds <- predict(tree.bayes, dtm, prior = c(0.5, 0.5), prob = TRUE)
data$MEDICAL_SCORE <- t(attr(tree.bayes.preds, "prob"))[,2]
data$MEDICAL_SCORE[is.nan(data$MEDICAL_SCORE)] <- 0
auc(data$APPROVAL, data$MEDICAL_SCORE)
rf = randomForest(
as.factor(APPROVAL)~AGE+LOG_AVG_RX_BILL+LOG_RX_CLAIMS+LOG_DEBIT_POINTS+MEDICAL_SCORE,
data,
keep.inbag = TRUE,
importance = TRUE,
sampsize = c(50,50) ,
mtry = 3,
strata = as.factor(data$APPROVAL),
ntree = 1000,
)
table(data$APPROVAL, rf$votes[,2] > 0.9)
auc(data$APPROVAL, rf$votes[,2])
data$CONFIDENCE <- rf$votes[,2]
data[data$CONFIDENCE >= 0.75,]
data[data$CONFIDENCE > 0.75,]
min(data$CONFIDENCE[data$APPROVAL == 1])
data[data$CONFIDENCE > 0.75,]
library(ggplot2)
library(dplyr)
lda <- LDA(dtm[data$CONFIDENCE > 0.75,1:500]), k = 10, control = list(seed = 1234))
lda <- LDA(dtm[data$CONFIDENCE > 0.75,1:500], k = 10, control = list(seed = 1234))
dtm[data$CONFIDENCE > 0.75,1:500]
lda <- LDA(dtm[data$CONFIDENCE > 0.75,1:500], k = 10, control = list(seed = 1234))
lda <- LDA(as.DocumentTermMatrix(dtm[data$CONFIDENCE > 0.75,1:500]), k = 10, control = list(seed = 1234))
gc()
data <- read.csv("G:\\My Drive\\HFI\\DataV12.csv")
library(randomForest)
library(forestFloor)
library(pROC)
library(bnlearn)
library(bnclassify)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(igraph)
library(lsa)
library(topicmodels)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(dplyr)
data$LOG_BILL <- log10(data$BILL + 1)
data$LOG_CLAIMS <- log10(data$CLAIMS + 1)
data$LOG_RX_BILL <- log10(data$RX_BILL)
data$LOG_RX_CLAIMS <- log10(data$RX_CLAIMS)
data$APPROVAL[is.na(data$APPROVAL)] <- 0
data$OUTREACH[is.na(data$OUTREACH)] <- 0
data$APPROVAL <- as.factor(data$APPROVAL)
data$MEMBER_ID <- as.character(data$MEMBER_ID)
data$DEBIT_POINTS[is.na(data$DEBIT_POINTS)] <- 0
data$LOG_DEBIT_POINTS <- log10(data$DEBIT_POINTS + 1)
data$LOG_AVG_BILL <- data$LOG_BILL - data$LOG_CLAIMS
data$LOG_AVG_RX_BILL <- data$LOG_RX_BILL - data$LOG_RX_CLAIMS
data$NUM_APPROVAL <- as.numeric(data$APPROVAL) - 1
data$INDEX <- seq.int(nrow(data))
quantities <- c("AGE", "LOG_AVG_RX_BILL", "LOG_RX_CLAIMS", "LOG_DEBIT_POINTS")
approval <- c("APPROVAL")
count <- nrow(data[data$APPROVAL == 1,])
corpus <- VCorpus(VectorSource(paste(data$DIAGNOSIS, data$REVENUE, sep = ' ')))
dtm <- DocumentTermMatrix(corpus, control =
list(tolower = TRUE,
removeNumbers = FALSE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE))
counts <- as.data.frame(matrix(0, ncol(dtm), 2))
row.names(counts) <- colnames(dtm)
colnames(counts) <- c("TOTAL", "APPROVAL_TOTAL")
for (i in 1:ncol(dtm)) {
counts$TOTAL[i] <- length(dtm[,i]$i)
counts$APPROVAL_TOTAL[i] <- sum(data$NUM_APPROVAL[dtm[,i]$i])
}
counts$CONFIDENCE <- 0
for (i in 1:nrow(counts)) {
test <- prop.test(c(counts$APPROVAL_TOTAL[i], count), c(counts$TOTAL[i], nrow(data)))
counts$CONFIDENCE[i] <- test$p.value
}
counts <- counts[order(counts$CONFIDENCE),]
dtm <- dtm[,row.names(counts)[1:1000]]
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
}
dtm <- apply(dtm, MARGIN = 2,convert_counts)
dtm.df <- as.data.frame(dtm)
for (i in 1:ncol(dtm.df)) {
dtm.df[,i] <- as.factor(dtm.df[,i])
}
dtm.df$APPROVAL <- as.factor(data$APPROVAL)
dtm <- as.DocumentTermMatrix(dtm)
dtm <- DocumentTermMatrix(dtm)
dtm <- as.DocumentTermMatrix(dtm)
dtm <- as.DocumentTermMatrix(dtm,weighting =
function(x)
weightTfIdf(x, normalize =
FALSE))
tree.bayes <- tree.bayes(dtm.df, approval, colnames(dtm.df)[-length(dtm.df)])
tree.bayes.preds <- predict(tree.bayes, dtm, prior = c(0.5, 0.5), prob = TRUE)
tree.bayes.preds <- predict(tree.bayes, dtm.df, prior = c(0.5, 0.5), prob = TRUE)
data$MEDICAL_SCORE <- t(attr(tree.bayes.preds, "prob"))[,2]
data$MEDICAL_SCORE[is.nan(data$MEDICAL_SCORE)] <- 0
auc(data$APPROVAL, data$MEDICAL_SCORE)
rf = randomForest(
as.factor(APPROVAL)~AGE+LOG_AVG_RX_BILL+LOG_RX_CLAIMS+LOG_DEBIT_POINTS+MEDICAL_SCORE,
data,
keep.inbag = TRUE,
importance = TRUE,
sampsize = c(50,50) ,
mtry = 3,
strata = as.factor(data$APPROVAL),
ntree = 1000,
)
table(data$APPROVAL, rf$votes[,2] > 0.9)
auc(data$APPROVAL, rf$votes[,2])
data$CONFIDENCE <- rf$votes[,2]
lda <- LDA(dtm[data$CONFIDENCE > 0.75,1:500], k = 10, control = list(seed = 1234))
dtm <- as.DocumentTermMatrix(dtm,weighting =
function(x)
weightTf(x, normalize =
FALSE))
lda <- LDA(dtm[data$CONFIDENCE > 0.75,1:500], k = 10, control = list(seed = 1234))
lda <- LDA(tm::weightTf(dtm[data$CONFIDENCE > 0.75,1:500]), k = 10, control = list(seed = 1234))
dtm <- tm::weightTf(dtm)
lda <- LDA(dtm[data$CONFIDENCE > 0.75,1:500], k = 10, control = list(seed = 1234))
gc()
data <- read.csv("G:\\My Drive\\HFI\\DataV12.csv")
library(randomForest)
library(forestFloor)
library(pROC)
library(bnlearn)
library(bnclassify)
library(tm)
library(SnowballC)
library(RColorBrewer)
library(igraph)
library(lsa)
library(topicmodels)
library(tidytext)
library(RColorBrewer)
library(ggplot2)
library(dplyr)
quantities <- c("AGE", "LOG_AVG_RX_BILL", "LOG_RX_CLAIMS", "LOG_DEBIT_POINTS")
approval <- c("APPROVAL")
count <- nrow(data[data$APPROVAL == 1,])
corpus <- VCorpus(VectorSource(paste(data$DIAGNOSIS, data$REVENUE, sep = ' ')))
dtm <- DocumentTermMatrix(corpus, control =
list(tolower = TRUE,
removeNumbers = FALSE,
stopwords = TRUE,
removePunctuation = TRUE,
stemming = TRUE))
counts <- as.data.frame(matrix(0, ncol(dtm), 2))
row.names(counts) <- colnames(dtm)
colnames(counts) <- c("TOTAL", "APPROVAL_TOTAL")
for (i in 1:ncol(dtm)) {
counts$TOTAL[i] <- length(dtm[,i]$i)
counts$APPROVAL_TOTAL[i] <- sum(data$NUM_APPROVAL[dtm[,i]$i])
}
counts$CONFIDENCE <- 0
for (i in 1:nrow(counts)) {
test <- prop.test(c(counts$APPROVAL_TOTAL[i], count), c(counts$TOTAL[i], nrow(data)))
counts$CONFIDENCE[i] <- test$p.value
}
counts <- counts[order(counts$CONFIDENCE),]
dtm <- dtm[,row.names(counts)[1:1000]]
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
}
dtm.df <- apply(dtm, MARGIN = 2,convert_counts)
dtm.df <- as.data.frame(dtm)
dtm.df <- as.data.frame(dtm.df)
for (i in 1:ncol(dtm.df)) {
dtm.df[,i] <- as.factor(dtm.df[,i])
}
dtm.df$APPROVAL <- as.factor(data$APPROVAL)
tree.bayes <- tree.bayes(dtm.df, approval, colnames(dtm.df)[-length(dtm.df)])
dtm.df
is.na(dtm.df)
colSums(is.na(dtm.df))
t(colSums(is.na(dtm.df)))
s <- colSums(is.na(dtm.df))
s[s>0]
data$APPROVAL
data$LOG_BILL <- log10(data$BILL + 1)
data$LOG_CLAIMS <- log10(data$CLAIMS + 1)
data$LOG_RX_BILL <- log10(data$RX_BILL)
data$LOG_RX_CLAIMS <- log10(data$RX_CLAIMS)
data$APPROVAL[is.na(data$APPROVAL)] <- 0
data$OUTREACH[is.na(data$OUTREACH)] <- 0
data$APPROVAL <- as.factor(data$APPROVAL)
data$MEMBER_ID <- as.character(data$MEMBER_ID)
data$DEBIT_POINTS[is.na(data$DEBIT_POINTS)] <- 0
data$LOG_DEBIT_POINTS <- log10(data$DEBIT_POINTS + 1)
data$LOG_AVG_BILL <- data$LOG_BILL - data$LOG_CLAIMS
data$LOG_AVG_RX_BILL <- data$LOG_RX_BILL - data$LOG_RX_CLAIMS
data$NUM_APPROVAL <- as.numeric(data$APPROVAL) - 1
data$INDEX <- seq.int(nrow(data))
dtm.df$APPROVAL <- as.factor(data$APPROVAL)
tree.bayes <- tree.bayes(dtm.df, approval, colnames(dtm.df)[-length(dtm.df)])
tree.bayes.preds <- predict(tree.bayes, dtm.df, prior = c(0.5, 0.5), prob = TRUE)
data$MEDICAL_SCORE <- t(attr(tree.bayes.preds, "prob"))[,2]
data$MEDICAL_SCORE[is.nan(data$MEDICAL_SCORE)] <- 0
auc(data$APPROVAL, data$MEDICAL_SCORE)
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
}
dtm.df <- apply(dtm, MARGIN = 2,convert_counts)
devtools::session_info(c('rmarkdown', 'tinytex'))
install.packages("devtools")
knitr::opts_chunk$set(echo = TRUE)
library(devtools)
devtools::session_info(c('rmarkdown', 'tinytex'))
knitr::opts_chunk$set(echo = TRUE)
library(devtools)
install.packages('tinytex')
tinytex::install_tinytex()
install.packages("tinytex")
knitr::opts_chunk$set(echo = TRUE)
library(devtools)
install.packages('tinytex')
tinytex::install_tinytex()
devtools::session_info(c('rmarkdown', 'tinytex'))
install.packages("devtools")
library(devtools)
install_version("rmarkdown",version=1.8)
